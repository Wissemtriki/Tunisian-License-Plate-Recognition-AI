{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licence Place Detection and Extraction with Deep Learning model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is used to detect the presence of a licence plate in the photo and extract it.\n",
    "In this module, we used a pretrained model that can detect the presence of the tunisian licence plate with the weights file named \"lapi.weights\".\n",
    "\n",
    "Use case:\n",
    "\n",
    "- The main objective of this module is to extract the licence plate (LP) from the input image and to send a cropped image of it to the module that will recognise its characters.\n",
    "\n",
    "- The second objective is to prepare a dataset containing the licence plates cropped for the data enrichment module that is necessary to improve the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "!!! Note: You should verify every path in this file before using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import argmax,uint8\n",
    "import os.path\n",
    "from cv2.dnn import readNetFromDarknet,DNN_BACKEND_OPENCV,DNN_TARGET_CPU,NMSBoxes,blobFromImage\n",
    "from cv2 import imwrite,rectangle,FILLED,putText,FONT_HERSHEY_SIMPLEX,getTextSize,VideoCapture,VideoWriter,VideoWriter_fourcc,CAP_PROP_FRAME_WIDTH,waitKey,getTickFrequency\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Licence Plate Detection - YOLO : Deep Learning object detection architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to detect licence we will use Yolo ( You Only Look Once ) deep learning object detection architecture \n",
    "based on convolution neural networks.\n",
    "This architecture was introduced by Joseph Redmon , Ali Farhadi, Ross Girshick and Santosh Divvala first version in 2015 and later version 2 and 3.\n",
    "\n",
    "Yolo v1 : Paper [link](https://arxiv.org/pdf/1506.02640.pdf).\n",
    "\n",
    "Yolo v2 : Paper [link](https://arxiv.org/pdf/1612.08242.pdf).\n",
    "\n",
    "Yolo v3 : Paper [link](https://arxiv.org/pdf/1804.02767.pdf).\n",
    "\n",
    "Yolo is a single network trained end to end to perform a regression task predicting both object bounding box and object class.\n",
    "This network is extremely fast, it processes images in real-time at 45 frames per second. A smaller version of the network, tiny YOLO, processes an astounding 155 frames per second.\n",
    "\n",
    "You will find more information about how to train Yolo on your customized dataset in this [Link](https://towardsdatascience.com/automatic-license-plate-detection-recognition-using-deep-learning-624def07eaaf).\n",
    "\n",
    "There is also other Deep learning object detector that you can use such as Single Shot Detector (SSD) and Faster RCNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters\n",
    "confThreshold = 0.5  #Confidence threshold\n",
    "nmsThreshold = 0.4  #Non-maximum suppression threshold\n",
    "\n",
    "inpWidth = 416  #608     #Width of network's input image\n",
    "inpHeight = 416 #608     #Height of network's input image\n",
    "\n",
    "directory=\"D:\\\\Horizop_version_1.0_LP_recog\\\\Horizop_version_1.0_LP_recog\\\\\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#If the image is given as a parameter via the command line $python script.py --image=path \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Licence Plate Detection using YOLO in OPENCV')\n",
    "parser.add_argument('--image', help='Path to image file.')\n",
    "#parser.add_argument('--video', help='Path to video file.') #this case is not defined in the function\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Load names of classes\n",
    "classesFile = \"D:\\\\Horizop_version_1.0_LP_recog\\\\Horizop_version_1.0_LP_recog\\\\Licence_plate_detection\\\\classes.names\";\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "\n",
    "modelConfiguration = directory+\"Licence_plate_detection\\\\darknet-yolov3.cfg\";\n",
    "modelWeights = directory+\"Licence_plate_detection\\\\lapi.weights\";\n",
    "\n",
    "net = readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom,frame):\n",
    "    # Draw a bounding box.\n",
    "    #    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    global LP_extracted\n",
    "    LP_extracted=frame[top+6:bottom-6, left+6:right-6]\n",
    "    imwrite(directory+\"Licence_Plate_extracted.jpg\",LP_extracted)     \t#extracting the licence plate\n",
    "    \n",
    "    rectangle(frame, (left, top), (right, bottom), (128, 190, 82), 3) #141, 214, 88\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "\n",
    "    rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (128, 190, 82), FILLED)\n",
    "    #cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine),    (255, 255, 255), cv.FILLED)\n",
    "    putText(frame, label, (left, top), FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n",
    "    #return(LP_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        #print(\"out.shape : \", out.shape)\n",
    "        for detection in out:\n",
    "            #if detection[4]>0.001:\n",
    "            scores = detection[5:]\n",
    "            classId = argmax(scores)\n",
    "            #if scores[classId]>confThreshold:\n",
    "            confidence = scores[classId]\n",
    "            #if detection[4]>confThreshold:\n",
    "                #print(detection[4], \" - \", scores[classId], \" - th : \", confThreshold)\n",
    "                #print(detection)\n",
    "            if confidence > confThreshold:\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    #print(\"indices\",type(indices))\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height,frame)\n",
    "        #print(\"i=\",i)\n",
    "        #print(\"box=\",box)\n",
    "        #PLicence=drawPred(classIds[i], confidences[i], left, top, left + width, top + height,frame)\n",
    "    return(top) #added to know where we will put the text in the final image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP_detection(image):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param:\n",
    "    the path of the vehicle image\n",
    "    \n",
    "    :return:\n",
    "    * if the licence plate exists in the photo, this function returns these parameters:\n",
    "        - LP_extracted : is the photo of the licence plate cropped \n",
    "        - frame.astype(uint8) : a new photo same as the input photo but containing a green box showing the presence of the LP \n",
    "        and indicating the score of the detection.\n",
    "        - top: is the top coordinate of the box, used in the recognition file to write on the photo the result of the licence plate\n",
    "        recognition.\n",
    "        \n",
    "    * else: this function returns None, None, None, which should be tested in the main script to interrupt the process before \n",
    "    the recognition.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if (image is not None):\n",
    "        print(image)\n",
    "        cap = VideoCapture(image)\n",
    "        hasFrame, frame = cap.read()\n",
    "        \n",
    "        # Create a 4D blob from a frame. \n",
    "        blob = blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "\n",
    "        # Sets the input to the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers\n",
    "        outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "        # Remove the bounding boxes with low confidence\n",
    "        #postprocess(frame, outs)\n",
    "        try:\n",
    "            top=postprocess(frame, outs)\n",
    "\n",
    "            # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n",
    "            t, _ = net.getPerfProfile()\n",
    "            label = 'Inference time: %.2f ms' % (t * 1000.0 / getTickFrequency())\n",
    "            #cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "\n",
    "\n",
    "            return LP_extracted ,frame.astype(uint8),top\n",
    "        except:\n",
    "            return None,None,None   #in this case, we don't have a licence plate in the photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Desktop\\win2.png\n",
      "indices <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Test of the LP extraction\n",
    "img= 'C:\\\\Users\\\\PC\\\\Desktop\\\\win2.png'\n",
    "a,b,c=LP_detection(img)\n",
    "if(a is not None and b is not None and c is not None):\n",
    "    cv2.imwrite(\"C:\\\\Users\\\\PC\\\\Desktop\\\\extracted.jpg\",a)\n",
    "else:\n",
    "    print(\"no lp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Extracting licence plates to prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the script to prepare a dataset containing the licence plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_folder=\"D:\\\\license_plates_detection_train\\\\license_plates_detection_train\" #the folder containing the vehicles\n",
    "LP_folder=\"D:\\\\datasets\\\\LP_TN\" #the output folder containing the LP extracted \n",
    "\n",
    "def extracting_LP(vehicle_folder,LP_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    :input: the folder containing the vehicles photos\n",
    "\n",
    "    :output: the folder that contains the result of cropping\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_items=len(glob.glob(\"{}\\\\*\".format(LP_folder)))+1\n",
    "    \n",
    "    for imagepath in glob.glob(\"{}\\\\*.*\".format(vehicle_folder)):\n",
    "        a,b,c=LP_detection(imagepath)\n",
    "            \n",
    "        if(a is not None and b is not None and c is not None):\n",
    "            cv2.imwrite(\"{}\\\\{}.jpg\".format(LP_folder,number_of_items),a)\n",
    "            number_of_items+=1\n",
    "        else: pass\n",
    "extracting_LP(vehicle_folder,LP_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_folder=\"D:\\\\datasets\\\\CAMERA ANPR COPY\\\\20160701\\\\\" #the folder containing the vehicles\n",
    "LP_folder=\"D:\\\\datasets\\\\LP_TN\" #the output folder containing the LP extracted \n",
    "\n",
    "def extracting_LP_nested_folders(vehicle_folder,LP_folder):\n",
    "    \"\"\"\n",
    "    :input: the folder containing the folders containing the vehicles photos\n",
    "\n",
    "    :output: the folder that contains the result of cropping\n",
    "    \n",
    "    In this function, we are doing the same thing as above but with nested folders like this example :\n",
    "    \n",
    "    ___ vehicle_folder:\n",
    "        \n",
    "        ______images000 :\n",
    "    \n",
    "            __________img1.jpg\n",
    "            ...\n",
    "            __________img200.jpg\n",
    "\n",
    "        ______images001\n",
    "        ...\n",
    "        ______images048\n",
    "\n",
    "    \"\"\"  \n",
    "    \n",
    "    number_of_items=len(glob.glob(\"{}\\\\*\".format(LP_folder)))+1\n",
    "    #j=len(glob.glob(\"{}\\\\*\".format(vehicle_folder)))\n",
    "    N=0\n",
    "    if(N<10):\n",
    "        ch=\"0\"+str(N)\n",
    "    else:\n",
    "        ch=str(N)\n",
    "    while(N<=48):\n",
    "        try:\n",
    "            for imagepath in glob.glob(\"{}\\\\{}\\\\*.*\".format(vehicle_folder,\"images0\"+ch)):\n",
    "                a,b,c=LP_detection(imagepath)\n",
    "\n",
    "                if(a is not None and b is not None and c is not None):\n",
    "                    cv2.imwrite(\"{}\\\\{}.jpg\".format(LP_folder,number_of_items),a)\n",
    "                    number_of_items+=1\n",
    "                else: pass\n",
    "        except: pass\n",
    "        N+=1\n",
    "extracting_LP_nested_folders(vehicle_folder,LP_folder)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ai_powered_license_plate_detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
